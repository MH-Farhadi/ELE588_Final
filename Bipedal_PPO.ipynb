{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 | Timesteps 1600 | Avg Loss: 0.2325 | Actor Loss: -0.0241 | Critic Loss: 0.2707 | Entropy: 1.4106\n",
      "Episode 1 | Timesteps 1657 | Avg Loss: 776.9959 | Actor Loss: -0.0084 | Critic Loss: 777.0183 | Entropy: 1.4048\n",
      "Episode 2 | Timesteps 1722 | Avg Loss: 730.8021 | Actor Loss: 0.0906 | Critic Loss: 730.7255 | Entropy: 1.4046\n",
      "Episode 3 | Timesteps 1804 | Avg Loss: 411.9441 | Actor Loss: -0.0130 | Critic Loss: 411.9711 | Entropy: 1.4046\n",
      "Episode 4 | Timesteps 1882 | Avg Loss: 353.5810 | Actor Loss: -0.0038 | Critic Loss: 353.5988 | Entropy: 1.4046\n",
      "Episode 5 | Timesteps 1941 | Avg Loss: 339.3087 | Actor Loss: -0.0021 | Critic Loss: 339.3249 | Entropy: 1.4046\n",
      "Episode 6 | Timesteps 1989 | Avg Loss: 342.5771 | Actor Loss: -0.0054 | Critic Loss: 342.5966 | Entropy: 1.4046\n",
      "Episode 7 | Timesteps 2033 | Avg Loss: 300.1006 | Actor Loss: -0.0087 | Critic Loss: 300.1233 | Entropy: 1.4046\n",
      "Episode 8 | Timesteps 2100 | Avg Loss: 186.4519 | Actor Loss: 0.1149 | Critic Loss: 186.3511 | Entropy: 1.4046\n",
      "Episode 9 | Timesteps 2174 | Avg Loss: 89.5036 | Actor Loss: -0.0155 | Critic Loss: 89.5331 | Entropy: 1.4046\n",
      "Episode 10 | Average Reward (last 10 episodes): -111.67 | Average Length: 217.40\n",
      "Episode 10 | Timesteps 2248 | Avg Loss: 64.4072 | Actor Loss: 0.0451 | Critic Loss: 64.3761 | Entropy: 1.4046\n",
      "Episode 11 | Timesteps 2298 | Avg Loss: 82.1738 | Actor Loss: 0.0023 | Critic Loss: 82.1855 | Entropy: 1.4046\n",
      "Episode 12 | Timesteps 2384 | Avg Loss: 46.2126 | Actor Loss: -0.0236 | Critic Loss: 46.2503 | Entropy: 1.4046\n",
      "Episode 13 | Timesteps 2456 | Avg Loss: 160.0468 | Actor Loss: 0.0005 | Critic Loss: 160.0604 | Entropy: 1.4045\n",
      "Episode 14 | Timesteps 4056 | Avg Loss: 6.4523 | Actor Loss: -0.0132 | Critic Loss: 6.4795 | Entropy: 1.4042\n",
      "Episode 15 | Timesteps 5656 | Avg Loss: 3.4512 | Actor Loss: -0.0125 | Critic Loss: 3.4778 | Entropy: 1.4039\n",
      "Episode 16 | Timesteps 5706 | Avg Loss: 312.5738 | Actor Loss: 0.0001 | Critic Loss: 312.5877 | Entropy: 1.4042\n",
      "Episode 17 | Timesteps 5809 | Avg Loss: 181.2624 | Actor Loss: -0.0249 | Critic Loss: 181.3013 | Entropy: 1.4042\n",
      "Episode 18 | Timesteps 5894 | Avg Loss: 152.0743 | Actor Loss: -0.0086 | Critic Loss: 152.0969 | Entropy: 1.4042\n",
      "Episode 19 | Timesteps 5966 | Avg Loss: 190.5478 | Actor Loss: -0.0249 | Critic Loss: 190.5867 | Entropy: 1.4042\n",
      "Episode 20 | Average Reward (last 10 episodes): -112.66 | Average Length: 379.20\n",
      "Episode 20 | Timesteps 7566 | Avg Loss: 5.9745 | Actor Loss: -0.0104 | Critic Loss: 5.9989 | Entropy: 1.4039\n",
      "Episode 21 | Timesteps 7674 | Avg Loss: 123.1794 | Actor Loss: -0.0035 | Critic Loss: 123.1969 | Entropy: 1.4032\n",
      "Episode 22 | Timesteps 9274 | Avg Loss: 5.8412 | Actor Loss: -0.0135 | Critic Loss: 5.8688 | Entropy: 1.4027\n",
      "Episode 23 | Timesteps 10874 | Avg Loss: 3.8575 | Actor Loss: -0.0082 | Critic Loss: 3.8797 | Entropy: 1.3998\n",
      "Episode 24 | Timesteps 12474 | Avg Loss: 2.2351 | Actor Loss: -0.0071 | Critic Loss: 2.2562 | Entropy: 1.3948\n",
      "Episode 25 | Timesteps 12554 | Avg Loss: 285.6183 | Actor Loss: -0.0229 | Critic Loss: 285.6550 | Entropy: 1.3906\n",
      "Episode 26 | Timesteps 12622 | Avg Loss: 329.8278 | Actor Loss: 0.0621 | Critic Loss: 329.7796 | Entropy: 1.3905\n",
      "Episode 27 | Timesteps 12703 | Avg Loss: 139.6532 | Actor Loss: 0.0247 | Critic Loss: 139.6424 | Entropy: 1.3905\n",
      "Episode 28 | Timesteps 12768 | Avg Loss: 177.9873 | Actor Loss: -0.0173 | Critic Loss: 178.0185 | Entropy: 1.3906\n",
      "Episode 29 | Timesteps 12832 | Avg Loss: 155.4042 | Actor Loss: -0.0046 | Critic Loss: 155.4227 | Entropy: 1.3906\n",
      "Episode 30 | Average Reward (last 10 episodes): -108.45 | Average Length: 686.60\n",
      "Episode 30 | Timesteps 12938 | Avg Loss: 65.9410 | Actor Loss: -0.0089 | Critic Loss: 65.9638 | Entropy: 1.3905\n",
      "Episode 31 | Timesteps 13007 | Avg Loss: 74.6575 | Actor Loss: -0.0231 | Critic Loss: 74.6946 | Entropy: 1.3905\n",
      "Episode 32 | Timesteps 13108 | Avg Loss: 16.3612 | Actor Loss: -0.0423 | Critic Loss: 16.4174 | Entropy: 1.3905\n",
      "Episode 33 | Timesteps 13200 | Avg Loss: 45.4345 | Actor Loss: -0.0280 | Critic Loss: 45.4764 | Entropy: 1.3905\n",
      "Episode 34 | Timesteps 14800 | Avg Loss: 7.0748 | Actor Loss: -0.0049 | Critic Loss: 7.0935 | Entropy: 1.3906\n",
      "Episode 35 | Timesteps 14873 | Avg Loss: 63.0379 | Actor Loss: -0.0272 | Critic Loss: 63.0789 | Entropy: 1.3908\n",
      "Episode 36 | Timesteps 14994 | Avg Loss: 54.1700 | Actor Loss: -0.0090 | Critic Loss: 54.1928 | Entropy: 1.3908\n",
      "Episode 37 | Timesteps 16594 | Avg Loss: 5.5144 | Actor Loss: -0.0103 | Critic Loss: 5.5387 | Entropy: 1.3915\n",
      "Episode 38 | Timesteps 18194 | Avg Loss: 4.0029 | Actor Loss: -0.0064 | Critic Loss: 4.0232 | Entropy: 1.3923\n",
      "Episode 39 | Timesteps 18281 | Avg Loss: 113.9784 | Actor Loss: 0.0296 | Critic Loss: 113.9628 | Entropy: 1.3922\n",
      "Episode 40 | Average Reward (last 10 episodes): -108.68 | Average Length: 544.90\n",
      "Episode 40 | Timesteps 18418 | Avg Loss: 45.1530 | Actor Loss: -0.0644 | Critic Loss: 45.2313 | Entropy: 1.3923\n",
      "Episode 41 | Timesteps 20018 | Avg Loss: 12.8171 | Actor Loss: -0.0093 | Critic Loss: 12.8403 | Entropy: 1.3917\n",
      "Episode 42 | Timesteps 20075 | Avg Loss: 117.9182 | Actor Loss: -0.0056 | Critic Loss: 117.9377 | Entropy: 1.3907\n",
      "Episode 43 | Timesteps 20156 | Avg Loss: 103.6675 | Actor Loss: -0.0368 | Critic Loss: 103.7183 | Entropy: 1.3908\n",
      "Episode 44 | Timesteps 20252 | Avg Loss: 58.0324 | Actor Loss: -0.0068 | Critic Loss: 58.0532 | Entropy: 1.3908\n",
      "Episode 45 | Timesteps 20314 | Avg Loss: 65.2363 | Actor Loss: 0.0026 | Critic Loss: 65.2477 | Entropy: 1.3907\n",
      "Episode 46 | Timesteps 21914 | Avg Loss: 7.5939 | Actor Loss: -0.0102 | Critic Loss: 7.6180 | Entropy: 1.3894\n",
      "Episode 47 | Timesteps 21964 | Avg Loss: 144.2292 | Actor Loss: -0.0238 | Critic Loss: 144.2668 | Entropy: 1.3877\n",
      "Episode 48 | Timesteps 22019 | Avg Loss: 104.9121 | Actor Loss: 0.0022 | Critic Loss: 104.9238 | Entropy: 1.3876\n",
      "Episode 49 | Timesteps 22082 | Avg Loss: 33.7713 | Actor Loss: -0.0006 | Critic Loss: 33.7858 | Entropy: 1.3875\n",
      "Episode 50 | Average Reward (last 10 episodes): -111.35 | Average Length: 380.10\n",
      "Episode 50 | Timesteps 22131 | Avg Loss: 30.2937 | Actor Loss: -0.0042 | Critic Loss: 30.3117 | Entropy: 1.3875\n",
      "Episode 51 | Timesteps 22192 | Avg Loss: 15.8048 | Actor Loss: -0.0118 | Critic Loss: 15.8305 | Entropy: 1.3873\n",
      "Episode 52 | Timesteps 22237 | Avg Loss: 7.2847 | Actor Loss: -0.0014 | Critic Loss: 7.3000 | Entropy: 1.3871\n",
      "Episode 53 | Timesteps 22295 | Avg Loss: 12.4045 | Actor Loss: -0.0187 | Critic Loss: 12.4371 | Entropy: 1.3871\n",
      "Episode 54 | Timesteps 22346 | Avg Loss: 4.1498 | Actor Loss: -0.0144 | Critic Loss: 4.1781 | Entropy: 1.3871\n",
      "Episode 55 | Timesteps 22434 | Avg Loss: 20.9827 | Actor Loss: 0.0160 | Critic Loss: 20.9806 | Entropy: 1.3871\n",
      "Episode 56 | Timesteps 22484 | Avg Loss: 20.6245 | Actor Loss: 0.0003 | Critic Loss: 20.6381 | Entropy: 1.3871\n",
      "Episode 57 | Timesteps 22537 | Avg Loss: 9.0636 | Actor Loss: -0.0051 | Critic Loss: 9.0825 | Entropy: 1.3872\n",
      "Episode 58 | Timesteps 24137 | Avg Loss: 16.5635 | Actor Loss: -0.0077 | Critic Loss: 16.5851 | Entropy: 1.3872\n",
      "Episode 59 | Timesteps 24186 | Avg Loss: 10.1444 | Actor Loss: -0.0065 | Critic Loss: 10.1648 | Entropy: 1.3870\n",
      "Episode 60 | Average Reward (last 10 episodes): -111.71 | Average Length: 210.40\n",
      "Episode 60 | Timesteps 24231 | Avg Loss: 5.2582 | Actor Loss: -0.0265 | Critic Loss: 5.2986 | Entropy: 1.3869\n",
      "Episode 61 | Timesteps 24291 | Avg Loss: 22.5277 | Actor Loss: -0.0174 | Critic Loss: 22.5589 | Entropy: 1.3868\n",
      "Episode 62 | Timesteps 24384 | Avg Loss: 15.8326 | Actor Loss: -0.0248 | Critic Loss: 15.8713 | Entropy: 1.3867\n",
      "Episode 63 | Timesteps 25655 | Avg Loss: 2.9929 | Actor Loss: -0.0141 | Critic Loss: 3.0209 | Entropy: 1.3852\n",
      "Episode 64 | Timesteps 25746 | Avg Loss: 71.0241 | Actor Loss: 0.0008 | Critic Loss: 71.0371 | Entropy: 1.3833\n",
      "Episode 65 | Timesteps 25831 | Avg Loss: 4.2981 | Actor Loss: -0.0138 | Critic Loss: 4.3257 | Entropy: 1.3830\n",
      "Episode 66 | Timesteps 25940 | Avg Loss: 11.8588 | Actor Loss: -0.0340 | Critic Loss: 11.9067 | Entropy: 1.3826\n",
      "Episode 67 | Timesteps 26032 | Avg Loss: 8.9104 | Actor Loss: -0.0187 | Critic Loss: 8.9429 | Entropy: 1.3826\n",
      "Episode 68 | Timesteps 26090 | Avg Loss: 20.0741 | Actor Loss: 0.0003 | Critic Loss: 20.0876 | Entropy: 1.3823\n",
      "Episode 69 | Timesteps 26188 | Avg Loss: 7.3871 | Actor Loss: -0.0401 | Critic Loss: 7.4410 | Entropy: 1.3821\n",
      "Episode 70 | Average Reward (last 10 episodes): -115.76 | Average Length: 200.20\n",
      "Episode 70 | Timesteps 27788 | Avg Loss: 9.5230 | Actor Loss: -0.0096 | Critic Loss: 9.5464 | Entropy: 1.3820\n",
      "Episode 71 | Timesteps 27846 | Avg Loss: 72.9409 | Actor Loss: -0.0034 | Critic Loss: 72.9581 | Entropy: 1.3827\n",
      "Episode 72 | Timesteps 27902 | Avg Loss: 7.8223 | Actor Loss: -0.0164 | Critic Loss: 7.8525 | Entropy: 1.3828\n",
      "Episode 73 | Timesteps 29502 | Avg Loss: 8.2329 | Actor Loss: -0.0127 | Critic Loss: 8.2594 | Entropy: 1.3819\n",
      "Episode 74 | Timesteps 29589 | Avg Loss: 15.8788 | Actor Loss: -0.0113 | Critic Loss: 15.9040 | Entropy: 1.3815\n",
      "Episode 75 | Timesteps 29654 | Avg Loss: 14.5866 | Actor Loss: -0.0079 | Critic Loss: 14.6083 | Entropy: 1.3811\n",
      "Episode 76 | Timesteps 31254 | Avg Loss: 6.0962 | Actor Loss: -0.0074 | Critic Loss: 6.1174 | Entropy: 1.3793\n",
      "Episode 77 | Timesteps 32854 | Avg Loss: 3.9695 | Actor Loss: -0.0068 | Critic Loss: 3.9900 | Entropy: 1.3762\n",
      "Episode 78 | Timesteps 34454 | Avg Loss: 2.9528 | Actor Loss: -0.0073 | Critic Loss: 2.9739 | Entropy: 1.3695\n",
      "Episode 79 | Timesteps 36054 | Avg Loss: 2.0449 | Actor Loss: -0.0071 | Critic Loss: 2.0656 | Entropy: 1.3622\n",
      "Episode 80 | Average Reward (last 10 episodes): -111.45 | Average Length: 986.60\n",
      "Episode 80 | Timesteps 37654 | Avg Loss: 1.5902 | Actor Loss: -0.0091 | Critic Loss: 1.6128 | Entropy: 1.3511\n",
      "Episode 81 | Timesteps 39254 | Avg Loss: 1.1412 | Actor Loss: -0.0076 | Critic Loss: 1.1622 | Entropy: 1.3370\n",
      "Episode 82 | Timesteps 39313 | Avg Loss: 116.7728 | Actor Loss: 0.0015 | Critic Loss: 116.7845 | Entropy: 1.3301\n",
      "Episode 83 | Timesteps 40913 | Avg Loss: 1.5479 | Actor Loss: -0.0096 | Critic Loss: 1.5708 | Entropy: 1.3263\n",
      "Episode 84 | Timesteps 42513 | Avg Loss: 0.7622 | Actor Loss: -0.0110 | Critic Loss: 0.7863 | Entropy: 1.3148\n",
      "Episode 85 | Timesteps 44113 | Avg Loss: 0.6295 | Actor Loss: -0.0089 | Critic Loss: 0.6514 | Entropy: 1.3039\n",
      "Episode 86 | Timesteps 45713 | Avg Loss: 0.4809 | Actor Loss: -0.0133 | Critic Loss: 0.5072 | Entropy: 1.2957\n",
      "Episode 87 | Timesteps 47313 | Avg Loss: 0.3459 | Actor Loss: -0.0102 | Critic Loss: 0.3689 | Entropy: 1.2842\n",
      "Episode 88 | Timesteps 48913 | Avg Loss: 0.3188 | Actor Loss: -0.0107 | Critic Loss: 0.3423 | Entropy: 1.2742\n",
      "Episode 89 | Timesteps 48979 | Avg Loss: 161.4745 | Actor Loss: -0.0935 | Critic Loss: 161.5807 | Entropy: 1.2716\n",
      "Episode 90 | Average Reward (last 10 episodes): -105.90 | Average Length: 1292.50\n",
      "Episode 90 | Timesteps 50579 | Avg Loss: 0.4835 | Actor Loss: -0.0099 | Critic Loss: 0.5061 | Entropy: 1.2700\n",
      "Episode 91 | Timesteps 52179 | Avg Loss: 0.3740 | Actor Loss: -0.0093 | Critic Loss: 0.3959 | Entropy: 1.2655\n",
      "Episode 92 | Timesteps 53779 | Avg Loss: 0.3708 | Actor Loss: -0.0123 | Critic Loss: 0.3958 | Entropy: 1.2614\n",
      "Episode 93 | Timesteps 55379 | Avg Loss: 0.2725 | Actor Loss: -0.0102 | Critic Loss: 0.2952 | Entropy: 1.2520\n",
      "Episode 94 | Timesteps 56979 | Avg Loss: 0.2207 | Actor Loss: -0.0096 | Critic Loss: 0.2427 | Entropy: 1.2396\n",
      "Episode 95 | Timesteps 57039 | Avg Loss: 264.5041 | Actor Loss: 0.0042 | Critic Loss: 264.5122 | Entropy: 1.2354\n",
      "Episode 96 | Timesteps 58639 | Avg Loss: 0.2472 | Actor Loss: -0.0091 | Critic Loss: 0.2686 | Entropy: 1.2292\n",
      "Episode 97 | Timesteps 60239 | Avg Loss: 0.2478 | Actor Loss: -0.0108 | Critic Loss: 0.2708 | Entropy: 1.2191\n",
      "Episode 98 | Timesteps 60320 | Avg Loss: 59.7779 | Actor Loss: -0.0216 | Critic Loss: 59.8116 | Entropy: 1.2157\n",
      "Episode 99 | Timesteps 61920 | Avg Loss: 0.5095 | Actor Loss: -0.0131 | Critic Loss: 0.5348 | Entropy: 1.2149\n",
      "Episode 100 | Average Reward (last 10 episodes): -100.50 | Average Length: 1294.10\n",
      "Episode 100 | Timesteps 63520 | Avg Loss: 0.2641 | Actor Loss: -0.0128 | Critic Loss: 0.2890 | Entropy: 1.2092\n",
      "Episode 101 | Timesteps 65120 | Avg Loss: 0.1913 | Actor Loss: -0.0166 | Critic Loss: 0.2200 | Entropy: 1.2011\n",
      "Episode 102 | Timesteps 66720 | Avg Loss: 0.1859 | Actor Loss: -0.0156 | Critic Loss: 0.2135 | Entropy: 1.1941\n",
      "Episode 103 | Timesteps 68320 | Avg Loss: 0.1809 | Actor Loss: -0.0145 | Critic Loss: 0.2074 | Entropy: 1.1890\n",
      "Episode 104 | Timesteps 69920 | Avg Loss: 0.1250 | Actor Loss: -0.0163 | Critic Loss: 0.1532 | Entropy: 1.1862\n",
      "Episode 105 | Timesteps 71520 | Avg Loss: 0.1198 | Actor Loss: -0.0189 | Critic Loss: 0.1505 | Entropy: 1.1827\n",
      "Episode 106 | Timesteps 73120 | Avg Loss: 0.1137 | Actor Loss: -0.0125 | Critic Loss: 0.1380 | Entropy: 1.1733\n",
      "Episode 107 | Timesteps 74720 | Avg Loss: 0.0753 | Actor Loss: -0.0111 | Critic Loss: 0.0980 | Entropy: 1.1640\n",
      "Episode 108 | Timesteps 76320 | Avg Loss: 0.0856 | Actor Loss: -0.0177 | Critic Loss: 0.1149 | Entropy: 1.1602\n",
      "Episode 109 | Timesteps 77920 | Avg Loss: 0.0898 | Actor Loss: -0.0159 | Critic Loss: 0.1173 | Entropy: 1.1558\n",
      "Episode 110 | Average Reward (last 10 episodes): -87.44 | Average Length: 1600.00\n",
      "Episode 110 | Timesteps 79520 | Avg Loss: 0.0657 | Actor Loss: -0.0172 | Critic Loss: 0.0944 | Entropy: 1.1503\n",
      "Episode 111 | Timesteps 79581 | Avg Loss: 323.8511 | Actor Loss: -0.0022 | Critic Loss: 323.8647 | Entropy: 1.1487\n",
      "Episode 112 | Timesteps 81181 | Avg Loss: 0.0980 | Actor Loss: -0.0169 | Critic Loss: 0.1264 | Entropy: 1.1435\n",
      "Episode 113 | Timesteps 82781 | Avg Loss: 0.0865 | Actor Loss: -0.0125 | Critic Loss: 0.1104 | Entropy: 1.1380\n",
      "Episode 114 | Timesteps 84381 | Avg Loss: 0.0729 | Actor Loss: -0.0175 | Critic Loss: 0.1017 | Entropy: 1.1252\n",
      "Episode 115 | Timesteps 85981 | Avg Loss: 0.0491 | Actor Loss: -0.0198 | Critic Loss: 0.0801 | Entropy: 1.1144\n",
      "Episode 116 | Timesteps 87581 | Avg Loss: 0.0723 | Actor Loss: -0.0181 | Critic Loss: 0.1014 | Entropy: 1.1072\n",
      "Episode 117 | Timesteps 89181 | Avg Loss: 0.0616 | Actor Loss: -0.0150 | Critic Loss: 0.0875 | Entropy: 1.0958\n",
      "Episode 118 | Timesteps 90781 | Avg Loss: 0.0569 | Actor Loss: -0.0210 | Critic Loss: 0.0888 | Entropy: 1.0884\n",
      "Episode 119 | Timesteps 92381 | Avg Loss: 0.0435 | Actor Loss: -0.0192 | Critic Loss: 0.0735 | Entropy: 1.0790\n",
      "Episode 120 | Average Reward (last 10 episodes): -74.63 | Average Length: 1446.10\n",
      "Episode 120 | Timesteps 93981 | Avg Loss: 0.0290 | Actor Loss: -0.0251 | Critic Loss: 0.0648 | Entropy: 1.0680\n",
      "Episode 121 | Timesteps 95581 | Avg Loss: 0.0364 | Actor Loss: -0.0243 | Critic Loss: 0.0714 | Entropy: 1.0599\n",
      "Episode 122 | Timesteps 95639 | Avg Loss: 297.1459 | Actor Loss: -0.0189 | Critic Loss: 297.1753 | Entropy: 1.0569\n",
      "Episode 123 | Timesteps 97239 | Avg Loss: 0.0479 | Actor Loss: -0.0288 | Critic Loss: 0.0872 | Entropy: 1.0544\n",
      "Episode 124 | Timesteps 98839 | Avg Loss: 0.0509 | Actor Loss: -0.0251 | Critic Loss: 0.0864 | Entropy: 1.0434\n",
      "Episode 125 | Timesteps 100439 | Avg Loss: 0.0319 | Actor Loss: -0.0248 | Critic Loss: 0.0670 | Entropy: 1.0283\n",
      "Episode 126 | Timesteps 102039 | Avg Loss: 0.0424 | Actor Loss: -0.0242 | Critic Loss: 0.0767 | Entropy: 1.0146\n",
      "Episode 127 | Timesteps 103639 | Avg Loss: 0.0433 | Actor Loss: -0.0272 | Critic Loss: 0.0806 | Entropy: 1.0070\n",
      "Episode 128 | Timesteps 105239 | Avg Loss: 0.0533 | Actor Loss: -0.0284 | Critic Loss: 0.0917 | Entropy: 1.0025\n",
      "Episode 129 | Timesteps 106839 | Avg Loss: 0.0479 | Actor Loss: -0.0272 | Critic Loss: 0.0851 | Entropy: 0.9964\n",
      "Episode 130 | Average Reward (last 10 episodes): -51.08 | Average Length: 1445.80\n",
      "Episode 130 | Timesteps 108439 | Avg Loss: 0.0299 | Actor Loss: -0.0303 | Critic Loss: 0.0701 | Entropy: 0.9916\n",
      "Episode 131 | Timesteps 108502 | Avg Loss: 218.6220 | Actor Loss: 0.0011 | Critic Loss: 218.6308 | Entropy: 0.9889\n",
      "Episode 132 | Timesteps 110102 | Avg Loss: 0.1431 | Actor Loss: -0.0220 | Critic Loss: 0.1749 | Entropy: 0.9845\n",
      "Episode 133 | Timesteps 111702 | Avg Loss: 0.0724 | Actor Loss: -0.0263 | Critic Loss: 0.1084 | Entropy: 0.9747\n",
      "Episode 134 | Timesteps 113302 | Avg Loss: 0.0468 | Actor Loss: -0.0281 | Critic Loss: 0.0846 | Entropy: 0.9642\n",
      "Episode 135 | Timesteps 114902 | Avg Loss: 0.0341 | Actor Loss: -0.0317 | Critic Loss: 0.0753 | Entropy: 0.9556\n",
      "Episode 136 | Timesteps 116502 | Avg Loss: 0.0267 | Actor Loss: -0.0301 | Critic Loss: 0.0662 | Entropy: 0.9475\n",
      "Episode 137 | Timesteps 118102 | Avg Loss: 0.0246 | Actor Loss: -0.0330 | Critic Loss: 0.0669 | Entropy: 0.9375\n",
      "Episode 138 | Timesteps 119702 | Avg Loss: 0.0260 | Actor Loss: -0.0338 | Critic Loss: 0.0690 | Entropy: 0.9303\n",
      "Episode 139 | Timesteps 121302 | Avg Loss: 0.0379 | Actor Loss: -0.0314 | Critic Loss: 0.0785 | Entropy: 0.9238\n",
      "Episode 140 | Average Reward (last 10 episodes): -12.70 | Average Length: 1446.30\n",
      "Episode 140 | Timesteps 122902 | Avg Loss: 0.0220 | Actor Loss: -0.0345 | Critic Loss: 0.0657 | Entropy: 0.9158\n",
      "Episode 141 | Timesteps 124502 | Avg Loss: 0.0151 | Actor Loss: -0.0327 | Critic Loss: 0.0568 | Entropy: 0.9002\n",
      "Episode 142 | Timesteps 126102 | Avg Loss: 0.0159 | Actor Loss: -0.0293 | Critic Loss: 0.0541 | Entropy: 0.8862\n",
      "Episode 143 | Timesteps 127702 | Avg Loss: 0.0175 | Actor Loss: -0.0305 | Critic Loss: 0.0568 | Entropy: 0.8722\n",
      "Episode 144 | Timesteps 129302 | Avg Loss: 0.0160 | Actor Loss: -0.0333 | Critic Loss: 0.0579 | Entropy: 0.8624\n",
      "Episode 145 | Timesteps 130902 | Avg Loss: 0.0162 | Actor Loss: -0.0277 | Critic Loss: 0.0525 | Entropy: 0.8519\n",
      "Episode 146 | Timesteps 132502 | Avg Loss: 0.0411 | Actor Loss: -0.0346 | Critic Loss: 0.0842 | Entropy: 0.8447\n",
      "Episode 147 | Timesteps 134102 | Avg Loss: 0.0440 | Actor Loss: -0.0331 | Critic Loss: 0.0854 | Entropy: 0.8346\n",
      "Episode 148 | Timesteps 135702 | Avg Loss: 0.0554 | Actor Loss: -0.0302 | Critic Loss: 0.0938 | Entropy: 0.8187\n",
      "Episode 149 | Timesteps 137302 | Avg Loss: 0.0320 | Actor Loss: -0.0342 | Critic Loss: 0.0743 | Entropy: 0.8082\n",
      "Episode 150 | Average Reward (last 10 episodes): 29.94 | Average Length: 1600.00\n",
      "Episode 150 | Timesteps 138902 | Avg Loss: 0.0513 | Actor Loss: -0.0303 | Critic Loss: 0.0897 | Entropy: 0.8031\n",
      "Episode 151 | Timesteps 140502 | Avg Loss: 0.0752 | Actor Loss: -0.0291 | Critic Loss: 0.1123 | Entropy: 0.7971\n",
      "Episode 152 | Timesteps 142102 | Avg Loss: 0.0281 | Actor Loss: -0.0359 | Critic Loss: 0.0719 | Entropy: 0.7866\n",
      "Episode 153 | Timesteps 142192 | Avg Loss: 174.4141 | Actor Loss: -0.0132 | Critic Loss: 174.4351 | Entropy: 0.7798\n",
      "Episode 154 | Timesteps 142297 | Avg Loss: 19.7521 | Actor Loss: -0.0240 | Critic Loss: 19.7839 | Entropy: 0.7798\n",
      "Episode 155 | Timesteps 143897 | Avg Loss: 0.2319 | Actor Loss: -0.0252 | Critic Loss: 0.2649 | Entropy: 0.7760\n",
      "Episode 156 | Timesteps 145497 | Avg Loss: 0.0265 | Actor Loss: -0.0285 | Critic Loss: 0.0626 | Entropy: 0.7692\n",
      "Episode 157 | Timesteps 147097 | Avg Loss: 0.0167 | Actor Loss: -0.0303 | Critic Loss: 0.0546 | Entropy: 0.7629\n",
      "Episode 158 | Timesteps 148697 | Avg Loss: 0.0112 | Actor Loss: -0.0333 | Critic Loss: 0.0520 | Entropy: 0.7539\n",
      "Episode 159 | Timesteps 150297 | Avg Loss: 0.0262 | Actor Loss: -0.0264 | Critic Loss: 0.0600 | Entropy: 0.7423\n",
      "Episode 160 | Average Reward (last 10 episodes): 22.22 | Average Length: 1299.50\n",
      "Episode 160 | Timesteps 150382 | Avg Loss: 149.0451 | Actor Loss: 0.0217 | Critic Loss: 149.0308 | Entropy: 0.7375\n",
      "Episode 161 | Timesteps 151982 | Avg Loss: 0.1618 | Actor Loss: -0.0260 | Critic Loss: 0.1951 | Entropy: 0.7346\n",
      "Episode 162 | Timesteps 153582 | Avg Loss: 0.0335 | Actor Loss: -0.0245 | Critic Loss: 0.0653 | Entropy: 0.7310\n",
      "Episode 163 | Timesteps 155182 | Avg Loss: 0.0155 | Actor Loss: -0.0297 | Critic Loss: 0.0524 | Entropy: 0.7227\n",
      "Episode 164 | Timesteps 156782 | Avg Loss: 0.2028 | Actor Loss: -0.0207 | Critic Loss: 0.2306 | Entropy: 0.7148\n",
      "Episode 165 | Timesteps 158382 | Avg Loss: 0.0722 | Actor Loss: -0.0222 | Critic Loss: 0.1015 | Entropy: 0.7078\n",
      "Episode 166 | Timesteps 158532 | Avg Loss: 29.5990 | Actor Loss: 0.0050 | Critic Loss: 29.6010 | Entropy: 0.7029\n",
      "Episode 167 | Timesteps 160132 | Avg Loss: 0.1333 | Actor Loss: -0.0294 | Critic Loss: 0.1697 | Entropy: 0.7004\n",
      "Episode 168 | Timesteps 161732 | Avg Loss: 0.0695 | Actor Loss: -0.0320 | Critic Loss: 0.1086 | Entropy: 0.6981\n",
      "Episode 169 | Timesteps 163332 | Avg Loss: 0.1013 | Actor Loss: -0.0254 | Critic Loss: 0.1337 | Entropy: 0.6988\n",
      "Episode 170 | Average Reward (last 10 episodes): 36.19 | Average Length: 1303.50\n",
      "Episode 170 | Timesteps 163385 | Avg Loss: 245.8515 | Actor Loss: -0.0031 | Critic Loss: 245.8616 | Entropy: 0.6981\n",
      "Episode 171 | Timesteps 164985 | Avg Loss: 0.0466 | Actor Loss: -0.0313 | Critic Loss: 0.0848 | Entropy: 0.6930\n",
      "Episode 172 | Timesteps 165066 | Avg Loss: 144.2329 | Actor Loss: -0.0019 | Critic Loss: 144.2417 | Entropy: 0.6860\n",
      "Episode 173 | Timesteps 166645 | Avg Loss: 3.0777 | Actor Loss: -0.0176 | Critic Loss: 3.1021 | Entropy: 0.6855\n",
      "Episode 174 | Timesteps 167491 | Avg Loss: 6.2490 | Actor Loss: -0.0047 | Critic Loss: 6.2605 | Entropy: 0.6855\n",
      "Episode 175 | Timesteps 169091 | Avg Loss: 0.1969 | Actor Loss: -0.0214 | Critic Loss: 0.2251 | Entropy: 0.6850\n",
      "Episode 176 | Timesteps 170691 | Avg Loss: 0.0382 | Actor Loss: -0.0277 | Critic Loss: 0.0727 | Entropy: 0.6783\n",
      "Episode 177 | Timesteps 172291 | Avg Loss: 0.2141 | Actor Loss: -0.0216 | Critic Loss: 0.2424 | Entropy: 0.6738\n",
      "Episode 178 | Timesteps 173891 | Avg Loss: 0.0506 | Actor Loss: -0.0287 | Critic Loss: 0.0860 | Entropy: 0.6714\n",
      "Episode 179 | Timesteps 175491 | Avg Loss: 0.1734 | Actor Loss: -0.0195 | Critic Loss: 0.1995 | Entropy: 0.6650\n",
      "Episode 180 | Average Reward (last 10 episodes): 32.12 | Average Length: 1215.90\n",
      "Episode 180 | Timesteps 177091 | Avg Loss: 0.1613 | Actor Loss: -0.0261 | Critic Loss: 0.1941 | Entropy: 0.6607\n",
      "Episode 181 | Timesteps 177204 | Avg Loss: 53.9832 | Actor Loss: 0.0010 | Critic Loss: 53.9887 | Entropy: 0.6591\n",
      "Episode 182 | Timesteps 177335 | Avg Loss: 45.4431 | Actor Loss: 0.0406 | Critic Loss: 45.4091 | Entropy: 0.6590\n",
      "Episode 183 | Timesteps 177441 | Avg Loss: 52.2444 | Actor Loss: -0.0151 | Critic Loss: 52.2660 | Entropy: 0.6590\n",
      "Episode 184 | Timesteps 179041 | Avg Loss: 0.5827 | Actor Loss: -0.0171 | Critic Loss: 0.6064 | Entropy: 0.6562\n",
      "Episode 185 | Timesteps 180641 | Avg Loss: 0.0827 | Actor Loss: -0.0269 | Critic Loss: 0.1161 | Entropy: 0.6516\n",
      "Episode 186 | Timesteps 182241 | Avg Loss: 0.0903 | Actor Loss: -0.0276 | Critic Loss: 0.1243 | Entropy: 0.6444\n",
      "Episode 187 | Timesteps 183841 | Avg Loss: 0.0455 | Actor Loss: -0.0271 | Critic Loss: 0.0789 | Entropy: 0.6325\n",
      "Episode 188 | Timesteps 185441 | Avg Loss: 0.0311 | Actor Loss: -0.0243 | Critic Loss: 0.0617 | Entropy: 0.6257\n",
      "Episode 189 | Timesteps 187041 | Avg Loss: 0.1189 | Actor Loss: -0.0226 | Critic Loss: 0.1477 | Entropy: 0.6150\n",
      "Episode 190 | Average Reward (last 10 episodes): 37.82 | Average Length: 1155.00\n",
      "Episode 190 | Timesteps 188641 | Avg Loss: 0.0362 | Actor Loss: -0.0333 | Critic Loss: 0.0756 | Entropy: 0.6044\n",
      "Episode 191 | Timesteps 190241 | Avg Loss: 0.1085 | Actor Loss: -0.0272 | Critic Loss: 0.1417 | Entropy: 0.5963\n",
      "Episode 192 | Timesteps 191841 | Avg Loss: 0.0567 | Actor Loss: -0.0240 | Critic Loss: 0.0866 | Entropy: 0.5873\n",
      "Episode 193 | Timesteps 193441 | Avg Loss: 0.0570 | Actor Loss: -0.0309 | Critic Loss: 0.0938 | Entropy: 0.5807\n",
      "Episode 194 | Timesteps 195041 | Avg Loss: 0.0937 | Actor Loss: -0.0253 | Critic Loss: 0.1248 | Entropy: 0.5737\n",
      "Episode 195 | Timesteps 196641 | Avg Loss: 0.0712 | Actor Loss: -0.0262 | Critic Loss: 0.1031 | Entropy: 0.5666\n",
      "Episode 196 | Timesteps 198241 | Avg Loss: 0.1272 | Actor Loss: -0.0310 | Critic Loss: 0.1639 | Entropy: 0.5582\n",
      "Episode 197 | Timesteps 199841 | Avg Loss: 0.0880 | Actor Loss: -0.0233 | Critic Loss: 0.1169 | Entropy: 0.5554\n",
      "Episode 198 | Timesteps 201441 | Avg Loss: 0.2039 | Actor Loss: -0.0285 | Critic Loss: 0.2379 | Entropy: 0.5524\n",
      "Episode 199 | Timesteps 203041 | Avg Loss: 0.2214 | Actor Loss: -0.0283 | Critic Loss: 0.2551 | Entropy: 0.5437\n",
      "Episode 200 | Average Reward (last 10 episodes): 130.10 | Average Length: 1600.00\n",
      "Episode 200 | Timesteps 204641 | Avg Loss: 0.1752 | Actor Loss: -0.0264 | Critic Loss: 0.2069 | Entropy: 0.5344\n",
      "Episode 201 | Timesteps 206241 | Avg Loss: 0.1382 | Actor Loss: -0.0211 | Critic Loss: 0.1645 | Entropy: 0.5273\n",
      "Episode 202 | Timesteps 207841 | Avg Loss: 0.1453 | Actor Loss: -0.0209 | Critic Loss: 0.1714 | Entropy: 0.5212\n",
      "Episode 203 | Timesteps 209441 | Avg Loss: 0.3725 | Actor Loss: -0.0224 | Critic Loss: 0.4000 | Entropy: 0.5157\n",
      "Episode 204 | Timesteps 211041 | Avg Loss: 0.1497 | Actor Loss: -0.0202 | Critic Loss: 0.1750 | Entropy: 0.5114\n",
      "Episode 205 | Timesteps 212641 | Avg Loss: 0.4271 | Actor Loss: -0.0213 | Critic Loss: 0.4535 | Entropy: 0.5052\n",
      "Episode 206 | Timesteps 214241 | Avg Loss: 0.2503 | Actor Loss: -0.0227 | Critic Loss: 0.2780 | Entropy: 0.5052\n",
      "Episode 207 | Timesteps 215841 | Avg Loss: 0.2083 | Actor Loss: -0.0187 | Critic Loss: 0.2320 | Entropy: 0.5036\n",
      "Episode 208 | Timesteps 216478 | Avg Loss: 5.4146 | Actor Loss: -0.0085 | Critic Loss: 5.4281 | Entropy: 0.5014\n",
      "Episode 209 | Timesteps 218078 | Avg Loss: 0.3363 | Actor Loss: -0.0246 | Critic Loss: 0.3659 | Entropy: 0.4985\n",
      "Episode 210 | Average Reward (last 10 episodes): 139.38 | Average Length: 1503.70\n",
      "Episode 210 | Timesteps 218874 | Avg Loss: 6.1570 | Actor Loss: -0.0209 | Critic Loss: 6.1829 | Entropy: 0.4966\n",
      "Episode 211 | Timesteps 220474 | Avg Loss: 0.4212 | Actor Loss: -0.0200 | Critic Loss: 0.4462 | Entropy: 0.4946\n",
      "Episode 212 | Timesteps 221021 | Avg Loss: 11.4931 | Actor Loss: -0.0058 | Critic Loss: 11.5038 | Entropy: 0.4930\n",
      "Episode 213 | Timesteps 222621 | Avg Loss: 0.4823 | Actor Loss: -0.0200 | Critic Loss: 0.5073 | Entropy: 0.4946\n",
      "Episode 214 | Timesteps 224221 | Avg Loss: 0.5080 | Actor Loss: -0.0215 | Critic Loss: 0.5345 | Entropy: 0.4942\n",
      "Episode 215 | Timesteps 225821 | Avg Loss: 0.1434 | Actor Loss: -0.0196 | Critic Loss: 0.1680 | Entropy: 0.4915\n",
      "Episode 216 | Timesteps 227421 | Avg Loss: 0.1480 | Actor Loss: -0.0255 | Critic Loss: 0.1784 | Entropy: 0.4896\n",
      "Episode 217 | Timesteps 229021 | Avg Loss: 0.2301 | Actor Loss: -0.0167 | Critic Loss: 0.2517 | Entropy: 0.4875\n",
      "Episode 218 | Timesteps 230621 | Avg Loss: 0.2246 | Actor Loss: -0.0243 | Critic Loss: 0.2537 | Entropy: 0.4829\n",
      "Episode 219 | Timesteps 232221 | Avg Loss: 0.3328 | Actor Loss: -0.0207 | Critic Loss: 0.3582 | Entropy: 0.4778\n",
      "Episode 220 | Average Reward (last 10 episodes): 131.55 | Average Length: 1414.30\n",
      "Episode 220 | Timesteps 233821 | Avg Loss: 0.5300 | Actor Loss: -0.0192 | Critic Loss: 0.5539 | Entropy: 0.4717\n",
      "Episode 221 | Timesteps 235421 | Avg Loss: 0.4162 | Actor Loss: -0.0185 | Critic Loss: 0.4394 | Entropy: 0.4666\n",
      "Episode 222 | Timesteps 237021 | Avg Loss: 0.5525 | Actor Loss: -0.0218 | Critic Loss: 0.5789 | Entropy: 0.4620\n",
      "Episode 223 | Timesteps 238621 | Avg Loss: 0.2200 | Actor Loss: -0.0244 | Critic Loss: 0.2490 | Entropy: 0.4561\n",
      "Episode 224 | Timesteps 240221 | Avg Loss: 0.2971 | Actor Loss: -0.0183 | Critic Loss: 0.3198 | Entropy: 0.4468\n",
      "Episode 225 | Timesteps 241821 | Avg Loss: 0.5543 | Actor Loss: -0.0211 | Critic Loss: 0.5798 | Entropy: 0.4425\n",
      "Episode 226 | Timesteps 243421 | Avg Loss: 0.2453 | Actor Loss: -0.0250 | Critic Loss: 0.2748 | Entropy: 0.4392\n",
      "Episode 227 | Timesteps 245021 | Avg Loss: 0.6750 | Actor Loss: -0.0179 | Critic Loss: 0.6973 | Entropy: 0.4359\n",
      "Episode 228 | Timesteps 246621 | Avg Loss: 0.1906 | Actor Loss: -0.0257 | Critic Loss: 0.2205 | Entropy: 0.4278\n",
      "Episode 229 | Timesteps 248221 | Avg Loss: 0.2357 | Actor Loss: -0.0300 | Critic Loss: 0.2699 | Entropy: 0.4202\n",
      "Episode 230 | Average Reward (last 10 episodes): 182.48 | Average Length: 1600.00\n",
      "Episode 230 | Timesteps 249821 | Avg Loss: 0.3757 | Actor Loss: -0.0277 | Critic Loss: 0.4076 | Entropy: 0.4164\n",
      "Episode 231 | Timesteps 251421 | Avg Loss: 0.4126 | Actor Loss: -0.0261 | Critic Loss: 0.4428 | Entropy: 0.4097\n",
      "Episode 232 | Timesteps 253021 | Avg Loss: 0.1908 | Actor Loss: -0.0294 | Critic Loss: 0.2243 | Entropy: 0.3990\n",
      "Episode 233 | Timesteps 253311 | Avg Loss: 46.6305 | Actor Loss: 0.0060 | Critic Loss: 46.6285 | Entropy: 0.3928\n",
      "Episode 234 | Timesteps 254911 | Avg Loss: 0.9427 | Actor Loss: -0.0183 | Critic Loss: 0.9649 | Entropy: 0.3941\n",
      "Episode 235 | Timesteps 256511 | Avg Loss: 0.1617 | Actor Loss: -0.0222 | Critic Loss: 0.1879 | Entropy: 0.3957\n",
      "Episode 236 | Timesteps 258111 | Avg Loss: 0.3994 | Actor Loss: -0.0255 | Critic Loss: 0.4288 | Entropy: 0.3973\n",
      "Episode 237 | Timesteps 259711 | Avg Loss: 0.3331 | Actor Loss: -0.0247 | Critic Loss: 0.3617 | Entropy: 0.3971\n",
      "Episode 238 | Timesteps 261311 | Avg Loss: 0.4810 | Actor Loss: -0.0226 | Critic Loss: 0.5075 | Entropy: 0.3915\n",
      "Episode 239 | Timesteps 262911 | Avg Loss: 0.2572 | Actor Loss: -0.0230 | Critic Loss: 0.2841 | Entropy: 0.3839\n",
      "Episode 240 | Average Reward (last 10 episodes): 161.00 | Average Length: 1469.00\n",
      "Episode 240 | Timesteps 264511 | Avg Loss: 0.3898 | Actor Loss: -0.0220 | Critic Loss: 0.4156 | Entropy: 0.3761\n",
      "Episode 241 | Timesteps 266111 | Avg Loss: 0.3563 | Actor Loss: -0.0191 | Critic Loss: 0.3791 | Entropy: 0.3708\n",
      "Episode 242 | Timesteps 267711 | Avg Loss: 0.5269 | Actor Loss: -0.0230 | Critic Loss: 0.5536 | Entropy: 0.3702\n",
      "Episode 243 | Timesteps 269311 | Avg Loss: 0.4021 | Actor Loss: -0.0254 | Critic Loss: 0.4311 | Entropy: 0.3632\n",
      "Episode 244 | Timesteps 270911 | Avg Loss: 0.3756 | Actor Loss: -0.0169 | Critic Loss: 0.3960 | Entropy: 0.3584\n",
      "Episode 245 | Timesteps 272511 | Avg Loss: 0.3568 | Actor Loss: -0.0228 | Critic Loss: 0.3831 | Entropy: 0.3592\n",
      "Episode 246 | Timesteps 273212 | Avg Loss: 11.9759 | Actor Loss: -0.0057 | Critic Loss: 11.9852 | Entropy: 0.3598\n",
      "Episode 247 | Timesteps 274812 | Avg Loss: 0.8224 | Actor Loss: -0.0209 | Critic Loss: 0.8469 | Entropy: 0.3626\n",
      "Episode 248 | Timesteps 276412 | Avg Loss: 0.6255 | Actor Loss: -0.0262 | Critic Loss: 0.6554 | Entropy: 0.3647\n",
      "Episode 249 | Timesteps 278012 | Avg Loss: 0.3241 | Actor Loss: -0.0321 | Critic Loss: 0.3597 | Entropy: 0.3597\n",
      "Episode 250 | Average Reward (last 10 episodes): 180.50 | Average Length: 1510.10\n",
      "Episode 250 | Timesteps 279612 | Avg Loss: 0.3996 | Actor Loss: -0.0238 | Critic Loss: 0.4270 | Entropy: 0.3512\n",
      "Episode 251 | Timesteps 281212 | Avg Loss: 0.3575 | Actor Loss: -0.0294 | Critic Loss: 0.3904 | Entropy: 0.3486\n",
      "Episode 252 | Timesteps 281786 | Avg Loss: 4.5993 | Actor Loss: -0.0116 | Critic Loss: 4.6144 | Entropy: 0.3479\n",
      "Episode 253 | Timesteps 283386 | Avg Loss: 0.3869 | Actor Loss: -0.0269 | Critic Loss: 0.4172 | Entropy: 0.3448\n",
      "Episode 254 | Timesteps 284986 | Avg Loss: 0.6733 | Actor Loss: -0.0286 | Critic Loss: 0.7053 | Entropy: 0.3350\n",
      "Episode 255 | Timesteps 286586 | Avg Loss: 0.4283 | Actor Loss: -0.0163 | Critic Loss: 0.4479 | Entropy: 0.3292\n",
      "Episode 256 | Timesteps 288186 | Avg Loss: 0.4727 | Actor Loss: -0.0213 | Critic Loss: 0.4973 | Entropy: 0.3276\n",
      "Episode 257 | Timesteps 288905 | Avg Loss: 2.6851 | Actor Loss: -0.0223 | Critic Loss: 2.7107 | Entropy: 0.3294\n",
      "Episode 258 | Timesteps 289099 | Avg Loss: 73.5398 | Actor Loss: 0.0391 | Critic Loss: 73.5039 | Entropy: 0.3288\n",
      "Episode 259 | Timesteps 290699 | Avg Loss: 1.0307 | Actor Loss: -0.0200 | Critic Loss: 1.0540 | Entropy: 0.3244\n",
      "Episode 260 | Average Reward (last 10 episodes): 129.89 | Average Length: 1268.70\n",
      "Episode 260 | Timesteps 290795 | Avg Loss: 103.9902 | Actor Loss: 0.0068 | Critic Loss: 103.9866 | Entropy: 0.3185\n",
      "Episode 261 | Timesteps 290903 | Avg Loss: 47.9238 | Actor Loss: 0.0002 | Critic Loss: 47.9268 | Entropy: 0.3183\n",
      "Episode 262 | Timesteps 292503 | Avg Loss: 2.1994 | Actor Loss: -0.0117 | Critic Loss: 2.2144 | Entropy: 0.3187\n",
      "Episode 263 | Timesteps 294103 | Avg Loss: 0.5909 | Actor Loss: -0.0121 | Critic Loss: 0.6062 | Entropy: 0.3198\n",
      "Episode 264 | Timesteps 294192 | Avg Loss: 204.0074 | Actor Loss: -0.0337 | Critic Loss: 204.0443 | Entropy: 0.3202\n",
      "Episode 265 | Timesteps 295792 | Avg Loss: 0.6551 | Actor Loss: -0.0141 | Critic Loss: 0.6725 | Entropy: 0.3204\n",
      "Episode 266 | Timesteps 297392 | Avg Loss: 0.2077 | Actor Loss: -0.0222 | Critic Loss: 0.2331 | Entropy: 0.3183\n",
      "Episode 267 | Timesteps 298992 | Avg Loss: 0.1777 | Actor Loss: -0.0249 | Critic Loss: 0.2058 | Entropy: 0.3115\n",
      "Episode 268 | Timesteps 300592 | Avg Loss: 0.1139 | Actor Loss: -0.0234 | Critic Loss: 0.1404 | Entropy: 0.3039\n",
      "Episode 269 | Timesteps 302192 | Avg Loss: 0.1355 | Actor Loss: -0.0227 | Critic Loss: 0.1611 | Entropy: 0.3004\n",
      "Episode 270 | Average Reward (last 10 episodes): 101.08 | Average Length: 1149.30\n",
      "Episode 270 | Timesteps 303792 | Avg Loss: 0.3470 | Actor Loss: -0.0233 | Critic Loss: 0.3733 | Entropy: 0.2974\n",
      "Episode 271 | Timesteps 303907 | Avg Loss: 66.9617 | Actor Loss: -0.0115 | Critic Loss: 66.9761 | Entropy: 0.2950\n",
      "Episode 272 | Timesteps 305507 | Avg Loss: 0.2600 | Actor Loss: -0.0205 | Critic Loss: 0.2834 | Entropy: 0.2942\n",
      "Episode 273 | Timesteps 307107 | Avg Loss: 0.3811 | Actor Loss: -0.0247 | Critic Loss: 0.4087 | Entropy: 0.2926\n",
      "Episode 274 | Timesteps 308707 | Avg Loss: 0.1550 | Actor Loss: -0.0252 | Critic Loss: 0.1831 | Entropy: 0.2879\n",
      "Episode 275 | Timesteps 308805 | Avg Loss: 162.5644 | Actor Loss: -0.0027 | Critic Loss: 162.5700 | Entropy: 0.2834\n",
      "Episode 276 | Timesteps 310405 | Avg Loss: 0.3222 | Actor Loss: -0.0228 | Critic Loss: 0.3478 | Entropy: 0.2822\n",
      "Episode 277 | Timesteps 312005 | Avg Loss: 0.2039 | Actor Loss: -0.0277 | Critic Loss: 0.2344 | Entropy: 0.2762\n",
      "Episode 278 | Timesteps 312112 | Avg Loss: 135.9899 | Actor Loss: 0.0603 | Critic Loss: 135.9323 | Entropy: 0.2718\n",
      "Episode 279 | Timesteps 313712 | Avg Loss: 0.4144 | Actor Loss: -0.0197 | Critic Loss: 0.4369 | Entropy: 0.2729\n",
      "Episode 280 | Average Reward (last 10 episodes): 105.33 | Average Length: 1152.00\n",
      "Episode 280 | Timesteps 315312 | Avg Loss: 0.2233 | Actor Loss: -0.0294 | Critic Loss: 0.2554 | Entropy: 0.2747\n",
      "Episode 281 | Timesteps 316912 | Avg Loss: 0.2918 | Actor Loss: -0.0233 | Critic Loss: 0.3179 | Entropy: 0.2771\n",
      "Episode 282 | Timesteps 318512 | Avg Loss: 0.1311 | Actor Loss: -0.0249 | Critic Loss: 0.1587 | Entropy: 0.2717\n",
      "Episode 283 | Timesteps 320112 | Avg Loss: 0.1671 | Actor Loss: -0.0223 | Critic Loss: 0.1921 | Entropy: 0.2665\n",
      "Episode 284 | Timesteps 321712 | Avg Loss: 0.3800 | Actor Loss: -0.0211 | Critic Loss: 0.4037 | Entropy: 0.2622\n",
      "Episode 285 | Timesteps 323312 | Avg Loss: 0.2984 | Actor Loss: -0.0189 | Critic Loss: 0.3199 | Entropy: 0.2577\n",
      "Episode 286 | Timesteps 324912 | Avg Loss: 0.3345 | Actor Loss: -0.0216 | Critic Loss: 0.3587 | Entropy: 0.2520\n",
      "Episode 287 | Timesteps 326512 | Avg Loss: 0.3933 | Actor Loss: -0.0254 | Critic Loss: 0.4212 | Entropy: 0.2452\n",
      "Episode 288 | Timesteps 328112 | Avg Loss: 0.4186 | Actor Loss: -0.0249 | Critic Loss: 0.4459 | Entropy: 0.2344\n",
      "Episode 289 | Timesteps 329712 | Avg Loss: 0.2315 | Actor Loss: -0.0119 | Critic Loss: 0.2457 | Entropy: 0.2271\n",
      "Episode 290 | Average Reward (last 10 episodes): 183.88 | Average Length: 1600.00\n",
      "Episode 290 | Timesteps 331312 | Avg Loss: 0.5009 | Actor Loss: -0.0206 | Critic Loss: 0.5238 | Entropy: 0.2287\n",
      "Episode 291 | Timesteps 332912 | Avg Loss: 0.5632 | Actor Loss: -0.0185 | Critic Loss: 0.5840 | Entropy: 0.2308\n",
      "Episode 292 | Timesteps 334512 | Avg Loss: 0.2265 | Actor Loss: -0.0176 | Critic Loss: 0.2464 | Entropy: 0.2278\n",
      "Episode 293 | Timesteps 336112 | Avg Loss: 0.3630 | Actor Loss: -0.0193 | Critic Loss: 0.3845 | Entropy: 0.2245\n",
      "Episode 294 | Timesteps 337712 | Avg Loss: 0.6368 | Actor Loss: -0.0211 | Critic Loss: 0.6602 | Entropy: 0.2257\n",
      "Episode 295 | Timesteps 339312 | Avg Loss: 0.6782 | Actor Loss: -0.0170 | Critic Loss: 0.6974 | Entropy: 0.2237\n",
      "Episode 296 | Timesteps 340912 | Avg Loss: 0.3176 | Actor Loss: -0.0201 | Critic Loss: 0.3400 | Entropy: 0.2249\n",
      "Episode 297 | Timesteps 342512 | Avg Loss: 0.3379 | Actor Loss: -0.0218 | Critic Loss: 0.3619 | Entropy: 0.2207\n",
      "Episode 298 | Timesteps 344112 | Avg Loss: 0.4395 | Actor Loss: -0.0142 | Critic Loss: 0.4559 | Entropy: 0.2138\n",
      "Episode 299 | Timesteps 345539 | Avg Loss: 1.1800 | Actor Loss: -0.0148 | Critic Loss: 1.1969 | Entropy: 0.2128\n",
      "Episode 300 | Average Reward (last 10 episodes): 192.92 | Average Length: 1582.70\n",
      "Episode 300 | Timesteps 347139 | Avg Loss: 0.5910 | Actor Loss: -0.0161 | Critic Loss: 0.6092 | Entropy: 0.2134\n",
      "Episode 301 | Timesteps 348739 | Avg Loss: 0.4285 | Actor Loss: -0.0219 | Critic Loss: 0.4525 | Entropy: 0.2097\n",
      "Episode 302 | Timesteps 350339 | Avg Loss: 0.4975 | Actor Loss: -0.0183 | Critic Loss: 0.5179 | Entropy: 0.2008\n",
      "Episode 303 | Timesteps 351939 | Avg Loss: 0.5393 | Actor Loss: -0.0176 | Critic Loss: 0.5589 | Entropy: 0.1975\n",
      "Episode 304 | Timesteps 352067 | Avg Loss: 37.2580 | Actor Loss: 0.0215 | Critic Loss: 37.2385 | Entropy: 0.1972\n",
      "Episode 305 | Timesteps 353667 | Avg Loss: 0.4872 | Actor Loss: -0.0153 | Critic Loss: 0.5046 | Entropy: 0.1982\n",
      "Episode 306 | Timesteps 355267 | Avg Loss: 0.3046 | Actor Loss: -0.0182 | Critic Loss: 0.3249 | Entropy: 0.1989\n",
      "Episode 307 | Timesteps 356867 | Avg Loss: 0.2885 | Actor Loss: -0.0201 | Critic Loss: 0.3105 | Entropy: 0.1977\n",
      "Episode 308 | Timesteps 358467 | Avg Loss: 0.1480 | Actor Loss: -0.0255 | Critic Loss: 0.1754 | Entropy: 0.1939\n",
      "Episode 309 | Timesteps 360067 | Avg Loss: 0.3290 | Actor Loss: -0.0210 | Critic Loss: 0.3520 | Entropy: 0.1967\n",
      "Episode 310 | Average Reward (last 10 episodes): 175.04 | Average Length: 1452.80\n",
      "Episode 310 | Timesteps 361608 | Avg Loss: 2.3827 | Actor Loss: -0.0092 | Critic Loss: 2.3939 | Entropy: 0.1978\n",
      "Episode 311 | Timesteps 363208 | Avg Loss: 0.3497 | Actor Loss: -0.0233 | Critic Loss: 0.3749 | Entropy: 0.1997\n",
      "Episode 312 | Timesteps 364808 | Avg Loss: 0.4992 | Actor Loss: -0.0165 | Critic Loss: 0.5177 | Entropy: 0.2020\n",
      "Episode 313 | Timesteps 364934 | Avg Loss: 52.4304 | Actor Loss: 0.0255 | Critic Loss: 52.4070 | Entropy: 0.2010\n",
      "Episode 314 | Timesteps 366534 | Avg Loss: 0.5846 | Actor Loss: -0.0211 | Critic Loss: 0.6077 | Entropy: 0.2004\n",
      "Episode 315 | Timesteps 368134 | Avg Loss: 0.2574 | Actor Loss: -0.0152 | Critic Loss: 0.2746 | Entropy: 0.1986\n",
      "Episode 316 | Timesteps 369734 | Avg Loss: 0.3458 | Actor Loss: -0.0178 | Critic Loss: 0.3656 | Entropy: 0.1973\n",
      "Episode 317 | Timesteps 371334 | Avg Loss: 0.2903 | Actor Loss: -0.0227 | Critic Loss: 0.3149 | Entropy: 0.1951\n",
      "Episode 318 | Timesteps 372934 | Avg Loss: 0.5041 | Actor Loss: -0.0207 | Critic Loss: 0.5267 | Entropy: 0.1893\n",
      "Episode 319 | Timesteps 374534 | Avg Loss: 0.4990 | Actor Loss: -0.0185 | Critic Loss: 0.5194 | Entropy: 0.1841\n",
      "Episode 320 | Average Reward (last 10 episodes): 150.19 | Average Length: 1446.70\n",
      "Episode 320 | Timesteps 376134 | Avg Loss: 0.5779 | Actor Loss: -0.0150 | Critic Loss: 0.5947 | Entropy: 0.1867\n",
      "Episode 321 | Timesteps 377734 | Avg Loss: 0.2707 | Actor Loss: -0.0206 | Critic Loss: 0.2931 | Entropy: 0.1814\n",
      "Episode 322 | Timesteps 379334 | Avg Loss: 0.2849 | Actor Loss: -0.0231 | Critic Loss: 0.3097 | Entropy: 0.1690\n",
      "Episode 323 | Timesteps 380934 | Avg Loss: 0.3519 | Actor Loss: -0.0235 | Critic Loss: 0.3771 | Entropy: 0.1655\n",
      "Episode 324 | Timesteps 382534 | Avg Loss: 0.2561 | Actor Loss: -0.0166 | Critic Loss: 0.2744 | Entropy: 0.1650\n",
      "Episode 325 | Timesteps 384134 | Avg Loss: 0.2178 | Actor Loss: -0.0238 | Critic Loss: 0.2432 | Entropy: 0.1621\n",
      "Episode 326 | Timesteps 385734 | Avg Loss: 0.2628 | Actor Loss: -0.0126 | Critic Loss: 0.2771 | Entropy: 0.1654\n",
      "Episode 327 | Timesteps 387334 | Avg Loss: 0.4158 | Actor Loss: -0.0179 | Critic Loss: 0.4354 | Entropy: 0.1627\n",
      "Episode 328 | Timesteps 388934 | Avg Loss: 0.5250 | Actor Loss: -0.0187 | Critic Loss: 0.5453 | Entropy: 0.1603\n",
      "Episode 329 | Timesteps 390534 | Avg Loss: 0.5990 | Actor Loss: -0.0095 | Critic Loss: 0.6101 | Entropy: 0.1639\n",
      "Episode 330 | Average Reward (last 10 episodes): 195.09 | Average Length: 1600.00\n",
      "Episode 330 | Timesteps 392134 | Avg Loss: 0.5429 | Actor Loss: -0.0163 | Critic Loss: 0.5608 | Entropy: 0.1629\n",
      "Episode 331 | Timesteps 393734 | Avg Loss: 0.3700 | Actor Loss: -0.0260 | Critic Loss: 0.3976 | Entropy: 0.1611\n",
      "Episode 332 | Timesteps 395334 | Avg Loss: 0.2824 | Actor Loss: -0.0234 | Critic Loss: 0.3073 | Entropy: 0.1597\n",
      "Episode 333 | Timesteps 396934 | Avg Loss: 0.6705 | Actor Loss: -0.0188 | Critic Loss: 0.6909 | Entropy: 0.1579\n",
      "Episode 334 | Timesteps 397454 | Avg Loss: 4.3541 | Actor Loss: -0.0006 | Critic Loss: 4.3563 | Entropy: 0.1556\n",
      "Episode 335 | Timesteps 399054 | Avg Loss: 0.5527 | Actor Loss: -0.0139 | Critic Loss: 0.5681 | Entropy: 0.1534\n",
      "Episode 336 | Timesteps 400654 | Avg Loss: 0.7006 | Actor Loss: -0.0180 | Critic Loss: 0.7201 | Entropy: 0.1501\n",
      "Episode 337 | Timesteps 402254 | Avg Loss: 0.3286 | Actor Loss: -0.0215 | Critic Loss: 0.3515 | Entropy: 0.1428\n",
      "Episode 338 | Timesteps 403854 | Avg Loss: 0.3906 | Actor Loss: -0.0131 | Critic Loss: 0.4051 | Entropy: 0.1402\n",
      "Episode 339 | Timesteps 405454 | Avg Loss: 0.6124 | Actor Loss: -0.0119 | Critic Loss: 0.6257 | Entropy: 0.1434\n",
      "Episode 340 | Average Reward (last 10 episodes): 174.45 | Average Length: 1492.00\n",
      "Episode 340 | Timesteps 407054 | Avg Loss: 0.2500 | Actor Loss: -0.0266 | Critic Loss: 0.2780 | Entropy: 0.1405\n",
      "Episode 341 | Timesteps 408654 | Avg Loss: 0.5347 | Actor Loss: -0.0215 | Critic Loss: 0.5576 | Entropy: 0.1377\n",
      "Episode 342 | Timesteps 410254 | Avg Loss: 0.3587 | Actor Loss: -0.0194 | Critic Loss: 0.3795 | Entropy: 0.1391\n",
      "Episode 343 | Timesteps 411854 | Avg Loss: 0.3632 | Actor Loss: -0.0230 | Critic Loss: 0.3875 | Entropy: 0.1363\n",
      "Episode 344 | Timesteps 413454 | Avg Loss: 0.4248 | Actor Loss: -0.0215 | Critic Loss: 0.4477 | Entropy: 0.1329\n",
      "Episode 345 | Timesteps 415054 | Avg Loss: 0.1721 | Actor Loss: -0.0311 | Critic Loss: 0.2046 | Entropy: 0.1353\n",
      "Episode 346 | Timesteps 416654 | Avg Loss: 0.4653 | Actor Loss: -0.0197 | Critic Loss: 0.4863 | Entropy: 0.1358\n",
      "Episode 347 | Timesteps 418254 | Avg Loss: 0.5793 | Actor Loss: -0.0237 | Critic Loss: 0.6044 | Entropy: 0.1378\n",
      "Episode 348 | Timesteps 419854 | Avg Loss: 0.6534 | Actor Loss: -0.0221 | Critic Loss: 0.6768 | Entropy: 0.1353\n",
      "Episode 349 | Timesteps 421454 | Avg Loss: 0.3691 | Actor Loss: -0.0227 | Critic Loss: 0.3931 | Entropy: 0.1265\n",
      "Episode 350 | Average Reward (last 10 episodes): 204.09 | Average Length: 1600.00\n",
      "Episode 350 | Timesteps 423054 | Avg Loss: 0.2797 | Actor Loss: -0.0253 | Critic Loss: 0.3062 | Entropy: 0.1206\n",
      "Episode 351 | Timesteps 424654 | Avg Loss: 0.2074 | Actor Loss: -0.0120 | Critic Loss: 0.2206 | Entropy: 0.1199\n",
      "Episode 352 | Timesteps 426254 | Avg Loss: 0.3802 | Actor Loss: -0.0238 | Critic Loss: 0.4052 | Entropy: 0.1209\n",
      "Episode 353 | Timesteps 427854 | Avg Loss: 0.3703 | Actor Loss: -0.0184 | Critic Loss: 0.3898 | Entropy: 0.1189\n",
      "Episode 354 | Timesteps 429454 | Avg Loss: 0.6484 | Actor Loss: -0.0197 | Critic Loss: 0.6694 | Entropy: 0.1173\n",
      "Episode 355 | Timesteps 431054 | Avg Loss: 0.6828 | Actor Loss: -0.0208 | Critic Loss: 0.7047 | Entropy: 0.1158\n",
      "Episode 356 | Timesteps 432654 | Avg Loss: 0.6742 | Actor Loss: -0.0220 | Critic Loss: 0.6974 | Entropy: 0.1133\n",
      "Episode 357 | Timesteps 434254 | Avg Loss: 0.3727 | Actor Loss: -0.0197 | Critic Loss: 0.3935 | Entropy: 0.1090\n",
      "Episode 358 | Timesteps 435854 | Avg Loss: 0.3972 | Actor Loss: -0.0215 | Critic Loss: 0.4197 | Entropy: 0.1028\n",
      "Episode 359 | Timesteps 437454 | Avg Loss: 0.5622 | Actor Loss: -0.0252 | Critic Loss: 0.5884 | Entropy: 0.0956\n",
      "Episode 360 | Average Reward (last 10 episodes): 219.87 | Average Length: 1600.00\n",
      "Episode 360 | Timesteps 439054 | Avg Loss: 0.7660 | Actor Loss: -0.0155 | Critic Loss: 0.7824 | Entropy: 0.0901\n",
      "Episode 361 | Timesteps 440654 | Avg Loss: 0.5504 | Actor Loss: -0.0204 | Critic Loss: 0.5717 | Entropy: 0.0833\n",
      "Episode 362 | Timesteps 442254 | Avg Loss: 0.3924 | Actor Loss: -0.0218 | Critic Loss: 0.4150 | Entropy: 0.0803\n",
      "Episode 363 | Timesteps 443854 | Avg Loss: 0.4490 | Actor Loss: -0.0213 | Critic Loss: 0.4712 | Entropy: 0.0811\n",
      "Episode 364 | Timesteps 445454 | Avg Loss: 0.3997 | Actor Loss: -0.0264 | Critic Loss: 0.4269 | Entropy: 0.0817\n",
      "Episode 365 | Timesteps 447054 | Avg Loss: 0.6136 | Actor Loss: -0.0183 | Critic Loss: 0.6327 | Entropy: 0.0824\n",
      "Episode 366 | Timesteps 448654 | Avg Loss: 0.5230 | Actor Loss: -0.0281 | Critic Loss: 0.5520 | Entropy: 0.0862\n",
      "Episode 367 | Timesteps 450254 | Avg Loss: 0.8302 | Actor Loss: -0.0138 | Critic Loss: 0.8449 | Entropy: 0.0887\n",
      "Episode 368 | Timesteps 451854 | Avg Loss: 0.4874 | Actor Loss: -0.0183 | Critic Loss: 0.5065 | Entropy: 0.0829\n",
      "Episode 369 | Timesteps 453454 | Avg Loss: 0.2863 | Actor Loss: -0.0237 | Critic Loss: 0.3109 | Entropy: 0.0812\n",
      "Episode 370 | Average Reward (last 10 episodes): 221.69 | Average Length: 1600.00\n",
      "Episode 370 | Timesteps 455054 | Avg Loss: 0.6226 | Actor Loss: -0.0272 | Critic Loss: 0.6506 | Entropy: 0.0774\n",
      "Episode 371 | Timesteps 456654 | Avg Loss: 0.4460 | Actor Loss: -0.0221 | Critic Loss: 0.4688 | Entropy: 0.0739\n",
      "Episode 372 | Timesteps 458254 | Avg Loss: 0.5900 | Actor Loss: -0.0217 | Critic Loss: 0.6123 | Entropy: 0.0675\n",
      "Episode 373 | Timesteps 459854 | Avg Loss: 0.9262 | Actor Loss: -0.0222 | Critic Loss: 0.9490 | Entropy: 0.0615\n",
      "Episode 374 | Timesteps 461454 | Avg Loss: 0.9495 | Actor Loss: -0.0254 | Critic Loss: 0.9755 | Entropy: 0.0582\n",
      "Episode 375 | Timesteps 463054 | Avg Loss: 0.5497 | Actor Loss: -0.0265 | Critic Loss: 0.5768 | Entropy: 0.0530\n",
      "Episode 376 | Timesteps 464654 | Avg Loss: 0.8480 | Actor Loss: -0.0172 | Critic Loss: 0.8657 | Entropy: 0.0488\n",
      "Episode 377 | Timesteps 466254 | Avg Loss: 0.6811 | Actor Loss: -0.0258 | Critic Loss: 0.7073 | Entropy: 0.0463\n",
      "Episode 378 | Timesteps 467854 | Avg Loss: 0.6414 | Actor Loss: -0.0191 | Critic Loss: 0.6609 | Entropy: 0.0423\n",
      "Episode 379 | Timesteps 469454 | Avg Loss: 0.3872 | Actor Loss: -0.0250 | Critic Loss: 0.4126 | Entropy: 0.0394\n",
      "Episode 380 | Average Reward (last 10 episodes): 220.50 | Average Length: 1600.00\n",
      "Episode 380 | Timesteps 471054 | Avg Loss: 0.6893 | Actor Loss: -0.0192 | Critic Loss: 0.7088 | Entropy: 0.0341\n",
      "Episode 381 | Timesteps 472654 | Avg Loss: 0.6231 | Actor Loss: -0.0192 | Critic Loss: 0.6425 | Entropy: 0.0291\n",
      "Episode 382 | Timesteps 474254 | Avg Loss: 0.3799 | Actor Loss: -0.0263 | Critic Loss: 0.4064 | Entropy: 0.0229\n",
      "Episode 383 | Timesteps 475854 | Avg Loss: 0.7023 | Actor Loss: -0.0217 | Critic Loss: 0.7242 | Entropy: 0.0202\n",
      "Episode 384 | Timesteps 477454 | Avg Loss: 0.6377 | Actor Loss: -0.0184 | Critic Loss: 0.6563 | Entropy: 0.0173\n",
      "Episode 385 | Timesteps 479054 | Avg Loss: 0.3684 | Actor Loss: -0.0335 | Critic Loss: 0.4019 | Entropy: 0.0100\n",
      "Episode 386 | Timesteps 480654 | Avg Loss: 0.7977 | Actor Loss: -0.0220 | Critic Loss: 0.8198 | Entropy: 0.0081\n",
      "Episode 387 | Timesteps 482254 | Avg Loss: 0.6560 | Actor Loss: -0.0229 | Critic Loss: 0.6791 | Entropy: 0.0126\n",
      "Episode 388 | Timesteps 483854 | Avg Loss: 0.7293 | Actor Loss: -0.0212 | Critic Loss: 0.7507 | Entropy: 0.0162\n",
      "Episode 389 | Timesteps 485454 | Avg Loss: 0.4403 | Actor Loss: -0.0217 | Critic Loss: 0.4621 | Entropy: 0.0148\n",
      "Episode 390 | Average Reward (last 10 episodes): 221.87 | Average Length: 1600.00\n",
      "Episode 390 | Timesteps 487054 | Avg Loss: 0.8181 | Actor Loss: -0.0227 | Critic Loss: 0.8409 | Entropy: 0.0117\n",
      "Episode 391 | Timesteps 488654 | Avg Loss: 0.3878 | Actor Loss: -0.0169 | Critic Loss: 0.4049 | Entropy: 0.0155\n",
      "Episode 392 | Timesteps 490254 | Avg Loss: 0.3380 | Actor Loss: -0.0179 | Critic Loss: 0.3561 | Entropy: 0.0194\n",
      "Episode 393 | Timesteps 491854 | Avg Loss: 0.1254 | Actor Loss: -0.0241 | Critic Loss: 0.1497 | Entropy: 0.0200\n",
      "Episode 394 | Timesteps 493454 | Avg Loss: 0.9394 | Actor Loss: -0.0205 | Critic Loss: 0.9601 | Entropy: 0.0195\n",
      "Episode 395 | Timesteps 495054 | Avg Loss: 0.4326 | Actor Loss: -0.0221 | Critic Loss: 0.4549 | Entropy: 0.0187\n",
      "Episode 396 | Timesteps 496654 | Avg Loss: 0.7467 | Actor Loss: -0.0201 | Critic Loss: 0.7670 | Entropy: 0.0191\n",
      "Episode 397 | Timesteps 498254 | Avg Loss: 0.4007 | Actor Loss: -0.0218 | Critic Loss: 0.4227 | Entropy: 0.0184\n",
      "Episode 398 | Timesteps 499854 | Avg Loss: 0.9982 | Actor Loss: -0.0166 | Critic Loss: 1.0150 | Entropy: 0.0147\n",
      "Episode 399 | Timesteps 501454 | Avg Loss: 0.4562 | Actor Loss: -0.0099 | Critic Loss: 0.4662 | Entropy: 0.0140\n",
      "Episode 400 | Average Reward (last 10 episodes): 234.58 | Average Length: 1600.00\n",
      "Episode 400 | Timesteps 503054 | Avg Loss: 0.8553 | Actor Loss: -0.0267 | Critic Loss: 0.8822 | Entropy: 0.0151\n",
      "Episode 401 | Timesteps 504654 | Avg Loss: 0.5761 | Actor Loss: -0.0172 | Critic Loss: 0.5935 | Entropy: 0.0171\n",
      "Episode 402 | Timesteps 506254 | Avg Loss: 0.3597 | Actor Loss: -0.0159 | Critic Loss: 0.3757 | Entropy: 0.0196\n",
      "Episode 403 | Timesteps 507854 | Avg Loss: 0.6961 | Actor Loss: -0.0193 | Critic Loss: 0.7155 | Entropy: 0.0155\n",
      "Episode 404 | Timesteps 509454 | Avg Loss: 0.4761 | Actor Loss: -0.0135 | Critic Loss: 0.4896 | Entropy: 0.0070\n",
      "Episode 405 | Timesteps 511054 | Avg Loss: 0.4654 | Actor Loss: -0.0166 | Critic Loss: 0.4820 | Entropy: 0.0040\n",
      "Episode 406 | Timesteps 512654 | Avg Loss: 0.9505 | Actor Loss: -0.0163 | Critic Loss: 0.9668 | Entropy: 0.0057\n",
      "Episode 407 | Timesteps 514254 | Avg Loss: 0.6099 | Actor Loss: -0.0179 | Critic Loss: 0.6278 | Entropy: -0.0003\n",
      "Episode 408 | Timesteps 515854 | Avg Loss: 0.4608 | Actor Loss: -0.0234 | Critic Loss: 0.4841 | Entropy: -0.0078\n",
      "Episode 409 | Timesteps 517454 | Avg Loss: 0.6434 | Actor Loss: -0.0228 | Critic Loss: 0.6662 | Entropy: -0.0070\n",
      "Episode 410 | Average Reward (last 10 episodes): 239.08 | Average Length: 1600.00\n",
      "Episode 410 | Timesteps 519054 | Avg Loss: 0.6324 | Actor Loss: -0.0201 | Critic Loss: 0.6524 | Entropy: -0.0052\n",
      "Episode 411 | Timesteps 520654 | Avg Loss: 0.8759 | Actor Loss: -0.0183 | Critic Loss: 0.8941 | Entropy: -0.0090\n",
      "Episode 412 | Timesteps 522254 | Avg Loss: 0.6834 | Actor Loss: -0.0107 | Critic Loss: 0.6941 | Entropy: -0.0110\n",
      "Episode 413 | Timesteps 523829 | Avg Loss: 0.9504 | Actor Loss: -0.0143 | Critic Loss: 0.9646 | Entropy: -0.0138\n",
      "Episode 414 | Timesteps 525429 | Avg Loss: 0.4288 | Actor Loss: -0.0183 | Critic Loss: 0.4469 | Entropy: -0.0149\n",
      "Episode 415 | Timesteps 527029 | Avg Loss: 0.9376 | Actor Loss: -0.0117 | Critic Loss: 0.9492 | Entropy: -0.0128\n",
      "Episode 416 | Timesteps 528629 | Avg Loss: 0.8915 | Actor Loss: -0.0223 | Critic Loss: 0.9137 | Entropy: -0.0118\n",
      "Episode 417 | Timesteps 530229 | Avg Loss: 0.7737 | Actor Loss: -0.0152 | Critic Loss: 0.7887 | Entropy: -0.0129\n",
      "Episode 418 | Timesteps 531798 | Avg Loss: 0.7327 | Actor Loss: -0.0135 | Critic Loss: 0.7461 | Entropy: -0.0133\n",
      "Episode 419 | Timesteps 533398 | Avg Loss: 0.4976 | Actor Loss: -0.0187 | Critic Loss: 0.5160 | Entropy: -0.0222\n",
      "Episode 420 | Average Reward (last 10 episodes): 245.20 | Average Length: 1594.40\n",
      "Episode 420 | Timesteps 534998 | Avg Loss: 0.7068 | Actor Loss: -0.0188 | Critic Loss: 0.7253 | Entropy: -0.0238\n",
      "Episode 421 | Timesteps 536598 | Avg Loss: 0.5760 | Actor Loss: -0.0237 | Critic Loss: 0.5994 | Entropy: -0.0232\n",
      "Episode 422 | Timesteps 538198 | Avg Loss: 0.3536 | Actor Loss: -0.0082 | Critic Loss: 0.3616 | Entropy: -0.0215\n",
      "Episode 423 | Timesteps 539798 | Avg Loss: 0.6581 | Actor Loss: -0.0334 | Critic Loss: 0.6912 | Entropy: -0.0247\n",
      "Episode 424 | Timesteps 541398 | Avg Loss: 0.8764 | Actor Loss: -0.0228 | Critic Loss: 0.8989 | Entropy: -0.0308\n",
      "Episode 425 | Timesteps 542998 | Avg Loss: 0.4040 | Actor Loss: -0.0228 | Critic Loss: 0.4263 | Entropy: -0.0375\n",
      "Episode 426 | Timesteps 544598 | Avg Loss: 0.4547 | Actor Loss: -0.0214 | Critic Loss: 0.4757 | Entropy: -0.0383\n",
      "Episode 427 | Timesteps 546198 | Avg Loss: 0.5936 | Actor Loss: -0.0209 | Critic Loss: 0.6141 | Entropy: -0.0405\n",
      "Episode 428 | Timesteps 547798 | Avg Loss: 0.4446 | Actor Loss: -0.0185 | Critic Loss: 0.4627 | Entropy: -0.0438\n",
      "Episode 429 | Timesteps 549398 | Avg Loss: 0.9499 | Actor Loss: -0.0181 | Critic Loss: 0.9675 | Entropy: -0.0444\n",
      "Episode 430 | Average Reward (last 10 episodes): 236.51 | Average Length: 1600.00\n",
      "Episode 430 | Timesteps 550998 | Avg Loss: 0.6569 | Actor Loss: -0.0195 | Critic Loss: 0.6759 | Entropy: -0.0480\n",
      "Episode 431 | Timesteps 552598 | Avg Loss: 1.0066 | Actor Loss: -0.0215 | Critic Loss: 1.0275 | Entropy: -0.0500\n",
      "Episode 432 | Timesteps 554198 | Avg Loss: 0.6109 | Actor Loss: -0.0194 | Critic Loss: 0.6298 | Entropy: -0.0519\n",
      "Episode 433 | Timesteps 555798 | Avg Loss: 0.7417 | Actor Loss: -0.0269 | Critic Loss: 0.7681 | Entropy: -0.0525\n",
      "Episode 434 | Timesteps 557398 | Avg Loss: 0.5997 | Actor Loss: -0.0207 | Critic Loss: 0.6198 | Entropy: -0.0529\n",
      "Episode 435 | Timesteps 558998 | Avg Loss: 0.8551 | Actor Loss: -0.0222 | Critic Loss: 0.8767 | Entropy: -0.0552\n",
      "Episode 436 | Timesteps 560598 | Avg Loss: 0.6053 | Actor Loss: -0.0247 | Critic Loss: 0.6294 | Entropy: -0.0613\n",
      "Episode 437 | Timesteps 562198 | Avg Loss: 0.6104 | Actor Loss: -0.0197 | Critic Loss: 0.6294 | Entropy: -0.0683\n",
      "Episode 438 | Timesteps 563798 | Avg Loss: 0.9061 | Actor Loss: -0.0183 | Critic Loss: 0.9236 | Entropy: -0.0729\n",
      "Episode 439 | Timesteps 565398 | Avg Loss: 0.4183 | Actor Loss: -0.0231 | Critic Loss: 0.4407 | Entropy: -0.0769\n",
      "Episode 440 | Average Reward (last 10 episodes): 236.27 | Average Length: 1600.00\n",
      "Episode 440 | Timesteps 566991 | Avg Loss: 0.7296 | Actor Loss: -0.0163 | Critic Loss: 0.7451 | Entropy: -0.0831\n",
      "Episode 441 | Timesteps 567041 | Avg Loss: 679.5212 | Actor Loss: 0.0510 | Critic Loss: 679.4693 | Entropy: -0.0856\n",
      "Episode 442 | Timesteps 568641 | Avg Loss: 0.6851 | Actor Loss: -0.0218 | Critic Loss: 0.7060 | Entropy: -0.0862\n",
      "Episode 443 | Timesteps 570241 | Avg Loss: 0.3953 | Actor Loss: -0.0165 | Critic Loss: 0.4109 | Entropy: -0.0882\n",
      "Episode 444 | Timesteps 571841 | Avg Loss: 0.3822 | Actor Loss: -0.0223 | Critic Loss: 0.4036 | Entropy: -0.0933\n",
      "Episode 445 | Timesteps 572930 | Avg Loss: 1.9545 | Actor Loss: 0.0055 | Critic Loss: 1.9480 | Entropy: -0.0962\n",
      "Episode 446 | Timesteps 574530 | Avg Loss: 0.4638 | Actor Loss: -0.0303 | Critic Loss: 0.4931 | Entropy: -0.0973\n",
      "Episode 447 | Timesteps 576130 | Avg Loss: 0.4976 | Actor Loss: -0.0187 | Critic Loss: 0.5152 | Entropy: -0.1017\n",
      "Episode 448 | Timesteps 576858 | Avg Loss: 5.4069 | Actor Loss: 0.0123 | Critic Loss: 5.3936 | Entropy: -0.1041\n",
      "Episode 449 | Timesteps 578458 | Avg Loss: 0.4969 | Actor Loss: -0.0267 | Critic Loss: 0.5226 | Entropy: -0.1031\n",
      "Episode 450 | Average Reward (last 10 episodes): 167.65 | Average Length: 1306.00\n",
      "Episode 450 | Timesteps 580058 | Avg Loss: 0.7700 | Actor Loss: -0.0194 | Critic Loss: 0.7883 | Entropy: -0.1103\n",
      "Episode 451 | Timesteps 581658 | Avg Loss: 0.4162 | Actor Loss: -0.0266 | Critic Loss: 0.4417 | Entropy: -0.1154\n",
      "Episode 452 | Timesteps 583258 | Avg Loss: 0.7806 | Actor Loss: -0.0194 | Critic Loss: 0.7989 | Entropy: -0.1158\n",
      "Episode 453 | Timesteps 584858 | Avg Loss: 0.4919 | Actor Loss: -0.0231 | Critic Loss: 0.5139 | Entropy: -0.1119\n",
      "Episode 454 | Timesteps 586458 | Avg Loss: 0.4381 | Actor Loss: -0.0261 | Critic Loss: 0.4631 | Entropy: -0.1111\n",
      "Episode 455 | Timesteps 588058 | Avg Loss: 0.4119 | Actor Loss: -0.0300 | Critic Loss: 0.4407 | Entropy: -0.1195\n",
      "Episode 456 | Timesteps 589658 | Avg Loss: 1.0286 | Actor Loss: -0.0241 | Critic Loss: 1.0515 | Entropy: -0.1243\n",
      "Episode 457 | Timesteps 591258 | Avg Loss: 0.8974 | Actor Loss: -0.0302 | Critic Loss: 0.9263 | Entropy: -0.1242\n",
      "Episode 458 | Timesteps 592853 | Avg Loss: 1.1925 | Actor Loss: -0.0189 | Critic Loss: 1.2102 | Entropy: -0.1270\n",
      "Episode 459 | Timesteps 594453 | Avg Loss: 0.1974 | Actor Loss: -0.0297 | Critic Loss: 0.2259 | Entropy: -0.1276\n",
      "Episode 460 | Average Reward (last 10 episodes): 242.29 | Average Length: 1599.50\n",
      "Episode 460 | Timesteps 596053 | Avg Loss: 0.3934 | Actor Loss: -0.0218 | Critic Loss: 0.4138 | Entropy: -0.1347\n",
      "Episode 461 | Timesteps 597599 | Avg Loss: 0.6598 | Actor Loss: -0.0151 | Critic Loss: 0.6735 | Entropy: -0.1414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 174\u001b[0m\n\u001b[0;32m    172\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m    173\u001b[0m action_clipped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(action, action_low, action_high)\n\u001b[1;32m--> 174\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mlog_prob(action)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    175\u001b[0m next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action_clipped\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    176\u001b[0m next_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(next_state)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\distributions\\normal.py:82\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# compute the variance\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     83\u001b[0m log_scale \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     84\u001b[0m     math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, Real) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m.\u001b[39mlog()\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;241m-\u001b[39m((value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m var)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;241m-\u001b[39m log_scale\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;241m-\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi))\n\u001b[0;32m     90\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_tensor.py:35\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[0;32m     33\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "ENV_NAME = 'BipedalWalker-v3'\n",
    "HIDDEN_SIZE = 256\n",
    "LEARNING_RATE = 3e-4\n",
    "GAMMA = 0.99\n",
    "LAMBDA = 0.95\n",
    "CLIP_EPSILON = 0.2\n",
    "ENTROPY_COEF = 0.01\n",
    "VALUE_LOSS_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "PPO_EPOCHS = 10\n",
    "MINI_BATCH_SIZE = 64\n",
    "TOTAL_EPISODES = 10_000  # Total number of episodes to train\n",
    "ROLLOUT_LENGTH = 2048\n",
    "EVAL_INTERVAL = 1000     # Evaluate every 1000 episodes\n",
    "EVAL_EPISODES = 5        # Number of episodes to run during evaluation\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10            # Number of evaluation intervals to wait for improvement\n",
    "min_delta = 1e-3         # Minimum change to consider as improvement\n",
    "\n",
    "# Device configuration (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize the environment with render_mode for evaluation\n",
    "env = gym.make(ENV_NAME)\n",
    "eval_env = gym.make(ENV_NAME, render_mode='human')  # Set render_mode to 'human' for rendering\n",
    "\n",
    "env.action_space.seed(seed)\n",
    "eval_env.action_space.seed(seed + 1)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.shape[0]\n",
    "action_high = torch.tensor(env.action_space.high).to(device)\n",
    "action_low = torch.tensor(env.action_space.low).to(device)\n",
    "\n",
    "# Define the Actor-Critic Network\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, obs_size, action_size):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        # Common network\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(obs_size, HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Actor network\n",
    "        self.actor_mean = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE, action_size),\n",
    "            nn.Tanh()  # Assuming action space is bounded between -1 and 1\n",
    "        )\n",
    "        # Actor log_std (learned)\n",
    "        self.actor_log_std = nn.Parameter(torch.zeros(action_size))\n",
    "        # Critic network\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared(x)\n",
    "        # Actor\n",
    "        mean = self.actor_mean(shared_out)\n",
    "        std = self.actor_log_std.exp().expand_as(mean)\n",
    "        dist = Normal(mean, std)\n",
    "        # Critic\n",
    "        value = self.critic(shared_out)\n",
    "        return dist, value\n",
    "\n",
    "# Initialize the network and optimizer\n",
    "model = ActorCritic(obs_size, action_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Storage for rollouts\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.obs = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.values = []\n",
    "\n",
    "    def clear(self):\n",
    "        self.obs = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.values = []\n",
    "\n",
    "buffer = RolloutBuffer()\n",
    "\n",
    "# Function to compute Generalized Advantage Estimation (GAE)\n",
    "def compute_gae(next_value, rewards, dones, values):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + GAMMA * values[step + 1] * (1 - dones[step]) - values[step]\n",
    "        gae = delta + GAMMA * LAMBDA * (1 - dones[step]) * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\n",
    "# Function to evaluate the agent\n",
    "def evaluate_policy(model, eval_env, episodes=5):\n",
    "    model.eval()\n",
    "    total_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        state, info = eval_env.reset(seed=seed + episode)\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        terminated = truncated = False\n",
    "        episode_reward = 0\n",
    "        while not (terminated or truncated):\n",
    "            with torch.no_grad():\n",
    "                dist, _ = model(state)\n",
    "                action = dist.mean\n",
    "            action_clipped = torch.clamp(action, action_low, action_high)\n",
    "            next_state, reward, terminated, truncated, _ = eval_env.step(action_clipped.cpu().numpy())\n",
    "            # Render the environment\n",
    "            eval_env.render()\n",
    "            state = torch.FloatTensor(next_state).to(device)\n",
    "            episode_reward += reward\n",
    "            time.sleep(0.01)  # Slow down the rendering\n",
    "        total_rewards.append(episode_reward)\n",
    "    model.train()\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Evaluation over {episodes} episodes: Average Reward = {avg_reward}\")\n",
    "    return avg_reward\n",
    "\n",
    "# Initialize variables for early stopping and tracking\n",
    "best_avg_reward = -np.inf\n",
    "no_improvement_counter = 0\n",
    "all_episode_rewards = []\n",
    "all_episode_lengths = []\n",
    "all_losses = []\n",
    "all_actor_losses = []\n",
    "all_critic_losses = []\n",
    "all_entropies = []\n",
    "all_avg_rewards = []\n",
    "episode_rewards = []\n",
    "episode_lengths = []\n",
    "total_timesteps = 0\n",
    "next_eval = EVAL_INTERVAL\n",
    "episode_count = 0\n",
    "\n",
    "while episode_count < TOTAL_EPISODES:\n",
    "    state, info = env.reset(seed=seed + episode_count)\n",
    "    state = torch.FloatTensor(state).to(device)\n",
    "    episode_reward = 0\n",
    "    episode_length = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        dist, value = model(state)\n",
    "        action = dist.sample()\n",
    "        action_clipped = torch.clamp(action, action_low, action_high)\n",
    "        log_prob = dist.log_prob(action).sum(dim=-1)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action_clipped.cpu().numpy())\n",
    "        next_state = torch.FloatTensor(next_state).to(device)\n",
    "        done = terminated or truncated\n",
    "        # Store in buffer (detach tensors to prevent retaining computational graph)\n",
    "        buffer.obs.append(state)\n",
    "        buffer.actions.append(action.detach())  # Detach action\n",
    "        buffer.log_probs.append(log_prob.detach())  # Detach log_prob\n",
    "        buffer.rewards.append(reward)\n",
    "        buffer.dones.append(done)\n",
    "        buffer.values.append(value.detach().squeeze())\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        episode_length += 1\n",
    "        total_timesteps += 1\n",
    "\n",
    "        # Check if it's time to update the policy\n",
    "        if len(buffer.rewards) >= ROLLOUT_LENGTH or done:\n",
    "            # Compute next value\n",
    "            with torch.no_grad():\n",
    "                _, next_value = model(state)\n",
    "            next_value = next_value.detach().squeeze()\n",
    "            # Compute returns and advantages\n",
    "            returns = compute_gae(next_value, buffer.rewards, buffer.dones, buffer.values)\n",
    "            advantages = [ret - val for ret, val in zip(returns, buffer.values)]\n",
    "            advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n",
    "            returns = torch.tensor(returns, dtype=torch.float32).to(device)\n",
    "\n",
    "            # Flatten the buffers\n",
    "            obs_tensor = torch.stack(buffer.obs)\n",
    "            actions_tensor = torch.stack(buffer.actions)\n",
    "            log_probs_tensor = torch.stack(buffer.log_probs)\n",
    "            values_tensor = torch.stack(buffer.values).to(device)\n",
    "            # Clear buffer\n",
    "            buffer.clear()\n",
    "\n",
    "            # Normalize advantages\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "            # PPO Optimization step\n",
    "            total_loss = 0\n",
    "            total_actor_loss = 0\n",
    "            total_critic_loss = 0\n",
    "            total_entropy = 0\n",
    "            num_updates = 0\n",
    "            for _ in range(PPO_EPOCHS):\n",
    "                # Create mini-batches\n",
    "                indices = np.arange(len(obs_tensor))\n",
    "                np.random.shuffle(indices)\n",
    "                for start in range(0, len(obs_tensor), MINI_BATCH_SIZE):\n",
    "                    end = start + MINI_BATCH_SIZE\n",
    "                    mini_batch_indices = indices[start:end]\n",
    "                    mb_obs = obs_tensor[mini_batch_indices]\n",
    "                    mb_actions = actions_tensor[mini_batch_indices]\n",
    "                    mb_log_probs = log_probs_tensor[mini_batch_indices]\n",
    "                    mb_returns = returns[mini_batch_indices]\n",
    "                    mb_advantages = advantages[mini_batch_indices]\n",
    "                    # Forward pass\n",
    "                    dist, value = model(mb_obs)\n",
    "                    entropy = dist.entropy().mean()\n",
    "                    new_log_probs = dist.log_prob(mb_actions).sum(dim=-1)\n",
    "                    # Ratio for clipping\n",
    "                    ratio = (new_log_probs - mb_log_probs).exp()\n",
    "                    surr1 = ratio * mb_advantages\n",
    "                    surr2 = torch.clamp(ratio, 1.0 - CLIP_EPSILON, 1.0 + CLIP_EPSILON) * mb_advantages\n",
    "                    actor_loss = -torch.min(surr1, surr2).mean()\n",
    "                    critic_loss = VALUE_LOSS_COEF * (mb_returns - value.squeeze()).pow(2).mean()\n",
    "                    loss = actor_loss + critic_loss - ENTROPY_COEF * entropy\n",
    "                    # Backpropagation\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "                    optimizer.step()\n",
    "                    # Accumulate losses\n",
    "                    total_loss += loss.item()\n",
    "                    total_actor_loss += actor_loss.item()\n",
    "                    total_critic_loss += critic_loss.item()\n",
    "                    total_entropy += entropy.item()\n",
    "                    num_updates += 1\n",
    "\n",
    "            # Compute average losses\n",
    "            avg_loss = total_loss / num_updates\n",
    "            avg_actor_loss = total_actor_loss / num_updates\n",
    "            avg_critic_loss = total_critic_loss / num_updates\n",
    "            avg_entropy = total_entropy / num_updates\n",
    "\n",
    "            # Store losses\n",
    "            all_losses.append(avg_loss)\n",
    "            all_actor_losses.append(avg_actor_loss)\n",
    "            all_critic_losses.append(avg_critic_loss)\n",
    "            all_entropies.append(avg_entropy)\n",
    "\n",
    "            # Verbose logging\n",
    "            print(f\"Episode {episode_count} | Timesteps {total_timesteps} | Avg Loss: {avg_loss:.4f} | \"\n",
    "                  f\"Actor Loss: {avg_actor_loss:.4f} | Critic Loss: {avg_critic_loss:.4f} | \"\n",
    "                  f\"Entropy: {avg_entropy:.4f}\")\n",
    "\n",
    "    episode_rewards.append(episode_reward)\n",
    "    episode_lengths.append(episode_length)\n",
    "    episode_count += 1\n",
    "\n",
    "    # Print average reward every 10 episodes\n",
    "    if episode_count % 10 == 0:\n",
    "        avg_reward = np.mean(episode_rewards[-10:])\n",
    "        avg_length = np.mean(episode_lengths[-10:])\n",
    "        print(f\"Episode {episode_count} | Average Reward (last 10 episodes): {avg_reward:.2f} | \"\n",
    "              f\"Average Length: {avg_length:.2f}\")\n",
    "\n",
    "    # Evaluate the agent periodically\n",
    "    if episode_count % EVAL_INTERVAL == 0:\n",
    "        print(f\"\\nEvaluating at episode {episode_count}...\")\n",
    "        avg_reward = evaluate_policy(model, eval_env, episodes=EVAL_EPISODES)\n",
    "        all_avg_rewards.append(avg_reward)\n",
    "\n",
    "        # Early stopping and model saving\n",
    "        if avg_reward > best_avg_reward + min_delta:\n",
    "            best_avg_reward = avg_reward\n",
    "            no_improvement_counter = 0\n",
    "            # Save the model\n",
    "            torch.save(model.state_dict(), f'best_model_episode_{episode_count}.pth')\n",
    "            print(f\"Best model saved with average reward {best_avg_reward} at episode {episode_count}\")\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            print(f\"No improvement for {no_improvement_counter} evaluation(s)\")\n",
    "\n",
    "        if no_improvement_counter >= patience:\n",
    "            print(f\"Early stopping at episode {episode_count} due to no improvement in average reward\")\n",
    "            break\n",
    "        print()\n",
    "\n",
    "env.close()\n",
    "eval_env.close()\n",
    "\n",
    "# Plotting the results\n",
    "episodes = range(len(episode_rewards))\n",
    "\n",
    "# Plot rewards\n",
    "plt.figure()\n",
    "plt.plot(episodes, episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Episode Reward Over Time')\n",
    "plt.savefig('rewards.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot losses\n",
    "plt.figure()\n",
    "plt.plot(range(len(all_losses)), all_losses, label='Total Loss')\n",
    "plt.plot(range(len(all_actor_losses)), all_actor_losses, label='Actor Loss')\n",
    "plt.plot(range(len(all_critic_losses)), all_critic_losses, label='Critic Loss')\n",
    "plt.xlabel('Policy Update')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses Over Time')\n",
    "plt.legend()\n",
    "plt.savefig('losses.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot average rewards during evaluation\n",
    "eval_episodes = [EVAL_INTERVAL * i for i in range(1, len(all_avg_rewards)+1)]\n",
    "plt.figure()\n",
    "plt.plot(eval_episodes, all_avg_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Average Reward During Evaluation')\n",
    "plt.savefig('avg_rewards.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
